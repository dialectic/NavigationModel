{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5jnePxz_Dk0L"
      },
      "outputs": [],
      "source": [
        "import keras \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os as os\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import LSTM\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otXY11pbDs0L",
        "outputId": "ab5e95f6-d1dc-4a8d-ccbd-8a76c9a24ff0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m174.1/176.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner"
      ],
      "metadata": {
        "id": "jYWoOd7TDwzf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Model**"
      ],
      "metadata": {
        "id": "Xv7z7uTrEJWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_existing_code(units, activation, dropout, lr):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=units, activation=activation))\n",
        "    if dropout:\n",
        "        model.add(layers.Dropout(rate=0.25))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='mse', metrics=['mae'],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "    units = hp.Int(\"units\", min_value=32, max_value=512, step=32)\n",
        "    activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
        "    dropout = hp.Boolean(\"dropout\")\n",
        "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "    # call existing model-building code with the hyperparameter values.\n",
        "    model = call_existing_code(\n",
        "        units=units, activation=activation, dropout=dropout, lr=lr\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "build_model(keras_tuner.HyperParameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4se3l0W_Dz1r",
        "outputId": "925dd9bb-9cad-4ece-ef06-6204ab243751"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f937341dc30>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Keras Tuner**"
      ],
      "metadata": {
        "id": "-eNFOQNzEfri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"mae\",\n",
        "    max_trials=3,\n",
        "    executions_per_trial=2,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"Regression\",\n",
        ")"
      ],
      "metadata": {
        "id": "7YbNoCs1ENcr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data PreProcess**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lGBsNw7zElq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "3DuMrE4tEeCE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Thesis/Notebook Modules/MoveData1.csv')  # import data"
      ],
      "metadata": {
        "id": "XyJr-iy3EtIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unwanted columns and do random shuffle of rows. \n",
        "newdf=df.sample(frac=1)\n",
        "newdf=newdf.reset_index(drop=True)\n",
        "newdf = newdf.drop(columns=['OM1X1', 'OM1X2',\n",
        "       'OM1X3', 'OM1X4', 'OM1X5', 'OM1X6', 'OM2X1', 'OM2X2', 'OM2X3', 'OM2X4',\n",
        "       'OM2X5', 'OM2X6'])\n",
        "newdf.head()"
      ],
      "metadata": {
        "id": "n7Kw7bkSEw5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seperate label column from data\n",
        "Label = pd.DataFrame(newdf['Label'])\n",
        "newdf = newdf.drop(columns=['Label'])"
      ],
      "metadata": {
        "id": "R36IXkBZE0x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seperate targets\n",
        "Target = pd.DataFrame(newdf[['VM1X1', 'VM1X2','VM1X3', 'VM1X4', 'VM1X5', 'VM1X6', 'VM2X1', 'VM2X2', 'VM2X3', 'VM2X4','VM2X5', 'VM2X6']])\n",
        "Input  = newdf.drop(columns=['VM1X1', 'VM1X2','VM1X3', 'VM1X4', 'VM1X5', 'VM1X6', 'VM2X1', 'VM2X2', 'VM2X3', 'VM2X4','VM2X5', 'VM2X6'])\n",
        "Input.head()"
      ],
      "metadata": {
        "id": "syuSXs4gE64w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "InputArray  = np.asarray(Input)\n",
        "TargetArray = np.asarray(Target)\n",
        "LabelArray  = np.asarray(Label) \n",
        "InputArray.shape"
      ],
      "metadata": {
        "id": "LTNcBNTlE-P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separate good bad\n",
        "badcount = 26522\n",
        "goodcount = InputArray.shape[0]-badcount\n",
        "\n",
        "GoodInput  = np.zeros([goodcount,24])\n",
        "GoodTarget = np.zeros([goodcount,12])\n",
        "\n",
        "row = InputArray.shape[0]\n",
        "i = 0\n",
        "m = 0\n",
        "while(i<row):\n",
        "  if(LabelArray[i]==1):\n",
        "    GoodInput[m] = InputArray[i]\n",
        "    GoodTarget[m] = TargetArray[i]\n",
        "    m=m+1\n",
        "    i=i+1\n",
        "  else:\n",
        "    i=i+1"
      ],
      "metadata": {
        "id": "nPuXn3x8FA9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_good = GoodInput\n",
        "Y_good = GoodTarget"
      ],
      "metadata": {
        "id": "hK_HMiqGFF3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = X_good[0:11739,:]\n",
        "test_data = X_good[11740:23477, :]\n",
        "train_targets = Y_good[0:11739,0]\n",
        "test_targets = Y_good[11740:23477,0]"
      ],
      "metadata": {
        "id": "8PIXowBeFIXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Model**"
      ],
      "metadata": {
        "id": "YxvkZCX9FMNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(train_data, train_targets, epochs=6, validation_data=(test_data, test_targets))"
      ],
      "metadata": {
        "id": "rUzsgnfeFOea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the top 2 hyperparameters.\n",
        "best_hps = tuner.get_best_hyperparameters(5)\n",
        "# Build the model with the best hp.\n",
        "model = build_model(best_hps[0])"
      ],
      "metadata": {
        "id": "BHG1fhUbFPni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply K fold\n",
        "k = 2\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores = []\n",
        "num_epochs = 500\n",
        "all_mae_histories = []"
      ],
      "metadata": {
        "id": "muhw06OWFTBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call backs\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "]"
      ],
      "metadata": {
        "id": "nUIzKZaBFZkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate(\n",
        "                        [train_data[:i * num_val_samples],\n",
        "                        train_data[(i + 1) * num_val_samples:]],\n",
        "                        axis=0)\n",
        "  partial_train_targets = np.concatenate(\n",
        "                        [train_targets[:i * num_val_samples],\n",
        "                        train_targets[(i + 1) * num_val_samples:]],\n",
        "                        axis=0)\n",
        "  #model = build_model()\n",
        "  history = model.fit(partial_train_data, partial_train_targets,\n",
        "  validation_data=(val_data, val_targets),\n",
        "  epochs=num_epochs, batch_size=1, verbose=0,callbacks=my_callbacks)\n",
        "  mae_history = history.history['mae']\n",
        "  all_mae_histories.append(mae_history)"
      ],
      "metadata": {
        "id": "VVxSbFBNFaVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "yUnlLeuuFe2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'Navigation_Train.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "iuUYgJugFfHu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}